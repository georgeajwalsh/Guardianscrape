{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Guardian API Key and Base URL\n",
    "API_KEY = \"998344a2-04a1-4410-9d53-1490cfa2e9d2\"\n",
    "BASE_URL = \"https://content.guardianapis.com/search\"\n",
    "\n",
    "# Output file\n",
    "FILE_NAME = \"guardian_articles.csv\"\n",
    "\n",
    "# Number of weeks to scrape\n",
    "NUM_WEEKS = 600\n",
    "ARTICLES_PER_WEEK = 5\n",
    "\n",
    "# Generate random weekly dates (going backward from today)\n",
    "start_date = datetime.today()\n",
    "dates = [(start_date - timedelta(weeks=i)).strftime(\"%Y-%m-%d\") for i in range(NUM_WEEKS)]\n",
    "\n",
    "# Load existing data if the file exists\n",
    "if os.path.exists(FILE_NAME):\n",
    "    df = pd.read_csv(FILE_NAME)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"headline\", \"publication_date\", \"url\"])\n",
    "\n",
    "# Fetch articles for each week\n",
    "for week_date in dates:\n",
    "    params = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"from-date\": week_date,\n",
    "        \"to-date\": week_date,\n",
    "        \"show-fields\": \"headline\",\n",
    "        \"page-size\": 10,  # Get up to 10 articles from the date\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data[\"response\"][\"results\"]\n",
    "        \n",
    "        if articles:\n",
    "            selected_article = random.choice(articles)  # Pick one randomly\n",
    "            article_data = {\n",
    "                \"headline\": selected_article[\"webTitle\"],\n",
    "                \"publication_date\": selected_article[\"webPublicationDate\"],\n",
    "                \"url\": selected_article[\"webUrl\"],\n",
    "            }\n",
    "\n",
    "            # Append new data and save\n",
    "            df = pd.concat([df, pd.DataFrame([article_data])], ignore_index=True)\n",
    "            df.to_csv(FILE_NAME, index=False)\n",
    "\n",
    "            print(f\"Saved article from {week_date}: {article_data['headline']}\")\n",
    "        else:\n",
    "            print(f\"No articles found for {week_date}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {week_date}: {response.status_code}\")\n",
    "\n",
    "print(\" Data collection complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this allows us to test the sucess of our scrapinng and ensure it has gone back 500 weeks also that it was effectively formatted\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Assuming 'df' is your dataframe with a 'publication_date' column in datetime format\n",
    "# Sample data:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Make sure 'publication_date' is in datetime format\n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'])\n",
    "\n",
    "# Remove timezone info if present\n",
    "df['publication_date'] = df['publication_date'].dt.tz_localize(None)\n",
    "\n",
    "# Extract Year-Month from publication_date\n",
    "df['year_month'] = df['publication_date'].dt.to_period('M')\n",
    "\n",
    "# Group by 'year_month' to count how many articles were published in each month\n",
    "monthly_data = df.groupby('year_month').size().reset_index(name='count')\n",
    "\n",
    "# Format the 'year_month' to show as 'Jan 18', 'Feb 18', etc.\n",
    "monthly_data['year_month_str'] = monthly_data['year_month'].dt.strftime('%b %y')\n",
    "\n",
    "# Create a list of distinct colors for each month (12 months in a year)\n",
    "month_colors = list(mcolors.TABLEAU_COLORS.values())  # Use Tableau colors, which are distinct\n",
    "\n",
    "# Map each month to a color\n",
    "# The color for each month will repeat, so January always gets the same color, February the same, etc.\n",
    "month_to_color = {month: month_colors[i % len(month_colors)] for i, month in enumerate(range(1, 13))}\n",
    "\n",
    "# Assign colors based on the month part of the 'year_month'\n",
    "monthly_data['color'] = monthly_data['year_month'].dt.month.map(month_to_color)\n",
    "\n",
    "# Sort the data by 'count' to identify the 10 smallest values\n",
    "sorted_data = monthly_data.sort_values(by='count')\n",
    "\n",
    "# Identify the 10 smallest values\n",
    "smallest_10 = sorted_data.head(10)\n",
    "\n",
    "# Assign red color to the 10 smallest values, blue to the rest\n",
    "monthly_data['color'] = monthly_data.apply(\n",
    "    lambda row: 'red' if row['year_month'] in smallest_10['year_month'].values else 'blue',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create a bar chart for the count of articles per month\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Create the bars with the assigned colors\n",
    "bars = plt.bar(monthly_data['year_month_str'], monthly_data['count'], color=monthly_data['color'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Article Count')\n",
    "plt.title('Monthly Data of Articles (Top 10 smallest counts in red)')\n",
    "\n",
    "# Rotate x-axis labels for better readability (vertical labels)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the bar chart\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Prepare the data\n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'])\n",
    "df['year_month'] = df['publication_date'].dt.to_period('M')\n",
    "df['month'] = df['publication_date'].dt.month_name()\n",
    "df['year'] = df['publication_date'].dt.year\n",
    "\n",
    "# Count headlines per month\n",
    "monthly_counts = df.groupby(['year_month', 'month']).size().reset_index(name='headline_count')\n",
    "\n",
    "# Create figure with two subplots\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Define a colour palette for months\n",
    "month_palette = {\n",
    "    'January': '#1f77b4', 'February': '#ff7f0e', 'March': '#2ca02c',\n",
    "    'April': '#d62728', 'May': '#9467bd', 'June': '#8c564b',\n",
    "    'July': '#e377c2', 'August': '#7f7f7f', 'September': '#bcbd22',\n",
    "    'October': '#17becf', 'November': '#aec7e8', 'December': '#ffbb78'\n",
    "}\n",
    "\n",
    "# Subplot 1: Overall distribution (single box)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=monthly_counts, y='headline_count', color='lightblue')\n",
    "plt.title('Overall Distribution of Monthly Headline Counts')\n",
    "plt.ylabel('Number of Headlines')\n",
    "plt.xlabel('All Months Combined')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Subplot 2: Monthly distribution (coloured by month)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(\n",
    "    data=monthly_counts,\n",
    "    x='month',\n",
    "    y='headline_count',\n",
    "    order=['January', 'February', 'March', 'April', 'May', 'June',\n",
    "           'July', 'August', 'September', 'October', 'November', 'December'],\n",
    "    palette=month_palette\n",
    ")\n",
    "plt.title('Monthly Distribution of Headline Counts')\n",
    "plt.ylabel('Number of Headlines')\n",
    "plt.xlabel('Month')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a custom legend for the colours\n",
    "legend_elements = [Patch(facecolor=month_palette[m], label=m) \n",
    "                  for m in month_palette]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df_gdp = pd.read_csv('/Users/georgewalsh/Desktop/API_NY/GDP.csv', skiprows=4)  # Skip the first 4 rows which contain metadata\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df_gdp.head()\n",
    "\n",
    "df_gdp_cleaned = df_gdp[['Country Name','2014','2015','2016','2017','2018','2019', '2020', '2021', '2022','2023']]\n",
    "df_gdp_cleaned.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
