{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Config\n",
    "API_KEY = \"998344a2-04a1-4410-9d53-1490cfa2e9d2\"\n",
    "BASE_URL = \"https://content.guardianapis.com/search\"\n",
    "FILE_NAME = \"guardian_articles.csv\"\n",
    "\n",
    "# Set date range\n",
    "start_year = 2014\n",
    "end_year = datetime.today().year\n",
    "total_years = end_year - start_year + 1\n",
    "total_weeks_to_scrape = 554  # total number of weeks/articles desired\n",
    "weeks_per_year = total_weeks_to_scrape // total_years\n",
    "\n",
    "# Create evenly spaced weekly dates per year\n",
    "def get_evenly_spaced_dates_for_year(year, weeks):\n",
    "    start = datetime(year, 1, 1)\n",
    "    end = datetime(year, 12, 31)\n",
    "    days_between = (end - start).days\n",
    "    step = days_between // weeks\n",
    "    return [(start + timedelta(days=i * step)).strftime(\"%Y-%m-%d\") for i in range(weeks)]\n",
    "\n",
    "# Generate list of evenly distributed dates\n",
    "all_dates = []\n",
    "for year in range(start_year, end_year + 1):\n",
    "    all_dates.extend(get_evenly_spaced_dates_for_year(year, weeks_per_year))\n",
    "\n",
    "# Shuffle to randomize request order\n",
    "random.shuffle(all_dates)\n",
    "\n",
    "# Load existing data if available\n",
    "if os.path.exists(FILE_NAME):\n",
    "    df = pd.read_csv(FILE_NAME)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"headline\", \"publication_date\", \"url\"])\n",
    "\n",
    "# Main loop to fetch articles\n",
    "for week_date in all_dates:\n",
    "    params = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"from-date\": week_date,\n",
    "        \"to-date\": week_date,\n",
    "        \"show-fields\": \"headline\",\n",
    "        \"page-size\": 10,\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data[\"response\"][\"results\"]\n",
    "\n",
    "        if articles:\n",
    "            selected_article = random.choice(articles)\n",
    "            article_data = {\n",
    "                \"headline\": selected_article[\"webTitle\"],\n",
    "                \"publication_date\": selected_article[\"webPublicationDate\"],\n",
    "                \"url\": selected_article[\"webUrl\"],\n",
    "            }\n",
    "\n",
    "            df = pd.concat([df, pd.DataFrame([article_data])], ignore_index=True)\n",
    "            df.to_csv(FILE_NAME, index=False)\n",
    "\n",
    "            print(f\"Saved article from {week_date}: {article_data['headline']}\")\n",
    "        else:\n",
    "            print(f\"No articles found for {week_date}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {week_date}: {response.status_code}\")\n",
    "\n",
    "print(\"Data collection complete!\")\n",
    "df.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1. Convert to datetime \n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'])\n",
    "\n",
    "# 2. Extract year and month\n",
    "df['year'] = df['publication_date'].dt.year\n",
    "df['month'] = df['publication_date'].dt.month_name()\n",
    "\n",
    "# 3. Count entries per year for the first plot\n",
    "year_counts = df['year'].value_counts().sort_index()\n",
    "year_index = year_counts.index.astype(str)\n",
    "year_values = year_counts.values\n",
    "\n",
    "# 4. Group by year and month to count entries for the second plot\n",
    "monthly_distribution = df.groupby(['year', 'month']).size().reset_index(name='count')\n",
    "\n",
    "# 5. Ensure consistent month order\n",
    "month_order = [\n",
    "    'January', 'February', 'March', 'April', 'May', 'June',\n",
    "    'July', 'August', 'September', 'October', 'November', 'December'\n",
    "]\n",
    "monthly_distribution['month'] = pd.Categorical(monthly_distribution['month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Create a figure with two subplots (1 row, 2 columns)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "\n",
    "# Generate unique colours\n",
    "colors = sns.color_palette(\"tab10\", len(year_counts))\n",
    "\n",
    "# Bar chart\n",
    "bars = axes[0].bar(\n",
    "    year_index,\n",
    "    year_values,\n",
    "    color=colors,\n",
    "    edgecolor='white',\n",
    "    width=0.6,\n",
    "    label='Entries'\n",
    ")\n",
    "\n",
    "# Smoothed line of best fit\n",
    "sns.lineplot(\n",
    "    x=year_index,\n",
    "    y=year_values,\n",
    "    color='red',\n",
    "    linewidth=1,\n",
    "    label='Trend',\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "# Add value labels above each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 1,\n",
    "        f'{height}',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "# Styling for the bar chart\n",
    "axes[0].set_title(\"Entries Per Year with Trend Line\", fontsize=16, weight='bold', pad=15)\n",
    "axes[0].set_xlabel(\"Years\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Number of Entries\", fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=0, labelsize=10)\n",
    "axes[0].tick_params(axis='y', labelsize=10)\n",
    "axes[0].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "sns.despine(top=True, right=True, ax=axes[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create boxplot\n",
    "sns.boxplot(\n",
    "    data=monthly_distribution,\n",
    "    x='month',\n",
    "    y='count',\n",
    "    palette='pastel',\n",
    "    linewidth=1.2,\n",
    "    fliersize=3,\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "# Calculate stats and annotate the boxplot\n",
    "for i, month in enumerate(month_order):\n",
    "    month_data = monthly_distribution[monthly_distribution['month'] == month]['count'].dropna()\n",
    "    if len(month_data) == 0:\n",
    "        continue\n",
    "\n",
    "    q1 = np.percentile(month_data, 25)\n",
    "    q3 = np.percentile(month_data, 75)\n",
    "    median = np.median(month_data)\n",
    "    whisker_low = month_data[month_data >= q1 - 1.5 * (q3 - q1)].min()\n",
    "    whisker_high = month_data[month_data <= q3 + 1.5 * (q3 - q1)].max()\n",
    "\n",
    "    # Annotate\n",
    "    axes[1].text(i, median + 2, f'Median: {int(median)}', ha='center', va='center', fontsize=7, color='black', weight='bold')\n",
    "    axes[1].text(i, q1, f'Q1: {int(q1)}', ha='center', va='top', fontsize=8, color='darkblue')\n",
    "    axes[1].text(i, q3, f'Q3: {int(q3)}', ha='center', va='bottom', fontsize=8, color='darkgreen')\n",
    "    axes[1].text(i, whisker_low, f'Min: {int(whisker_low)}', ha='center', va='top', fontsize=8, color='gray')\n",
    "    axes[1].text(i, whisker_high, f'Max: {int(whisker_high)}', ha='center', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "# Styling for the boxplot\n",
    "axes[1].set_title(\"Box Plot of Monthly Entry Counts Across Years\", fontsize=16, weight='bold', pad=20)\n",
    "axes[1].set_xlabel(\"Month\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Number of Entries per Year\", fontsize=12)\n",
    "axes[1].tick_params(axis='x', rotation=45, labelsize=10)\n",
    "axes[1].tick_params(axis='y', labelsize=10)\n",
    "axes[1].grid(axis='y', linestyle='--', alpha=0.4)\n",
    "sns.despine(top=True, right=True, ax=axes[1])\n",
    "\n",
    "# Final adjustments for layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "# Step 1: Combine all headlines into a single string\n",
    "text = \" \".join(headline for headline in df['headline'].dropna())\n",
    "\n",
    "# Step 2: Clean up stopwords and irrelevant words\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"s\", \"said\", \"mr\", \"mrs\",\n",
    "                  \"says\",\"will\",\"happened\",\"review\",\n",
    "                  \"quick\",\"U\",\"new\",\"crossword\", \"Cryptic\",\"\"\n",
    "                  \"day\",\"call\",\"year\"])  # Add more custom stopwords if needed\n",
    "\n",
    "# Step 3: Create the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400,\n",
    "                      background_color='white',\n",
    "                      stopwords=stopwords,\n",
    "                      colormap='viridis').generate(text)\n",
    "\n",
    "# Step 4: Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Most Frequent Words in Headlines (2013-2023)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footy=pd.read_csv(\"/Users/georgewalsh/Documents/premier-league-matches.csv\")\n",
    "df_footy_filtered = df_footy[df_footy['Season_End_Year'] >= 2016]\n",
    "\n",
    "# Home team wins\n",
    "home_wins = df_footy_filtered[df_footy_filtered['HomeGoals'] > df_footy_filtered['AwayGoals']]\n",
    "home_win_counts = home_wins['Home'].value_counts()\n",
    "\n",
    "# Away team wins\n",
    "away_wins = df_footy_filtered[df_footy_filtered['AwayGoals'] > df_footy_filtered['HomeGoals']]\n",
    "away_win_counts = away_wins['Away'].value_counts()\n",
    "\n",
    "# Combine home and away wins\n",
    "total_wins = home_win_counts.add(away_win_counts, fill_value=0).astype(int)\n",
    "\n",
    "# Create the new DataFrame\n",
    "df_team_wins = total_wins.reset_index()\n",
    "df_team_wins.columns = ['team', 'wins']\n",
    "\n",
    "# Sort by number of wins \n",
    "df_team_wins = df_team_wins.sort_values(by='wins', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#matches the years of data availablilty\n",
    "df_2023 = df[(df['year'] >= 2015) & (df['year'] <= 2023)]\n",
    "\n",
    "\n",
    "df_team_wins.head()\n",
    "\n",
    "#add the years we are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x=df_team_wins['wins'], y=np.arange(len(df_team_wins)), ci=None, lw=2, color=\"black\", estimator=None)\n",
    "\n",
    "for team, wins in zip(df_team_wins['team'], df_team_wins['wins']):\n",
    "    plt.hlines(y=team, xmin=0, xmax=wins, color=color_dict[team], linewidth=2)\n",
    "    plt.plot(wins, team, \"o\", color=color_dict[team], markersize=8)\n",
    "    plt.text(wins + offset, team, str(wins), va='center', ha='left', fontsize=10, color='black')\n",
    "\n",
    "plt.xlabel(\"Total Wins \")\n",
    "plt.title(\"Total Wins by Team (2015-2023)\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(0, 230, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Second plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.lineplot(x=df_mentions['mentions'], y=np.arange(len(df_mentions)), lw=2, color=\"black\", estimator=None, errorbar=None)\n",
    "\n",
    "for team in df_mentions['team']:\n",
    "    if team not in color_dict:\n",
    "        color_dict[team] = 'grey'\n",
    "\n",
    "for team, mentions in zip(df_mentions['team'], df_mentions['mentions']):\n",
    "    plt.hlines(y=team, xmin=0, xmax=mentions, color=color_dict[team], linewidth=2)\n",
    "    plt.plot(mentions, team, \"o\", color=color_dict[team], markersize=8)\n",
    "    plt.text(mentions + offset, team, str(mentions), va='center', ha='left', fontsize=10, color='black')\n",
    "\n",
    "plt.xlabel(\"Number of Mentions in Headlines \")\n",
    "plt.title(\"Premier League Team Mentions in Headlines (2013-2023) \", fontsize=14)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(0, 190, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Third plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Merge the data\n",
    "df_combined = pd.merge(df_team_wins, df_mentions, on='team', how='inner')\n",
    "\n",
    "# Create scatter plot with smaller points (size=50 instead of 100)\n",
    "for team in df_combined['team']:\n",
    "    plt.scatter(\n",
    "        df_combined[df_combined['team'] == team]['mentions'],\n",
    "        df_combined[df_combined['team'] == team]['wins'],\n",
    "        color=color_dict[team],\n",
    "        s=50  # Reduced point size\n",
    "    )\n",
    "\n",
    "# Add red regression line\n",
    "sns.regplot(\n",
    "    x='mentions',\n",
    "    y='wins',\n",
    "    data=df_combined,\n",
    "    scatter=False,\n",
    "    color='red',  # Changed to red\n",
    "    line_kws={'linestyle': '--', 'alpha': 0.7}\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Number of Mentions in Headlines\")\n",
    "plt.ylabel(\"Total Wins (2015-2023)\")\n",
    "plt.title(\"Relationship Between Team Wins and Media Mentions\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print correlation\n",
    "correlation = df_combined['wins'].corr(df_combined['mentions'])\n",
    "print(f\"\\nCorrelation between wins and mentions: {correlation:.3f}\")\n",
    "\n",
    "# Interpretation\n",
    "if abs(correlation) > 0.7:\n",
    "    strength = \"strong\"\n",
    "elif abs(correlation) > 0.3:\n",
    "    strength = \"moderate\"\n",
    "else:\n",
    "    strength = \"weak\"\n",
    "\n",
    "direction = \"positive\" if correlation > 0 else \"negative\"\n",
    "print(f\"This indicates a {strength} {direction} correlation between team wins and media mentions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df_gdp = pd.read_csv('/Users/georgewalsh/Desktop/API_NY/GDP.csv', skiprows=4)  # Skip the first 4 rows which contain metadata\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "\n",
    "\n",
    "df_gdp_cleaned = df_gdp[['Country Name','2014','2015','2016','2017','2018','2019', '2020', '2021', '2022','2023']]\n",
    "\n",
    "\n",
    "# Convert all GDP values (2019-2023) to numeric (integers or floats)\n",
    "gdp_columns = ['2014','2015','2016','2017','2018','2019', '2020', '2021', '2022', '2023']\n",
    "df_gdp_cleaned[gdp_columns] = df_gdp_cleaned[gdp_columns].apply(pd.to_numeric, errors='coerce')  # Convert values\n",
    "\n",
    "# Create a new column summarizing the total GDP over all years\n",
    "df_gdp_cleaned['Total GDP'] = df_gdp_cleaned[gdp_columns].sum(axis=1)\n",
    "\n",
    "df_gdp_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this allows us to incorporate the smoothed line of best fit\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "import re\n",
    "# Define our target countries (in the order we want them displayed)\n",
    "target_countries = [\n",
    "    'United States', 'China', 'Japan', 'Germany', \n",
    "    'India', 'United Kingdom', 'France', 'Italy',\n",
    "    'Canada', 'Brazil', 'Russia', 'South Korea'\n",
    "]\n",
    "# Country variants to search for in headlines\n",
    "country_variants = {\n",
    "    'United States': ['United States', 'USA', 'US', 'America'],\n",
    "    'United Kingdom': ['United Kingdom', 'UK', 'Britain'],\n",
    "    'China': ['China'],\n",
    "    'Japan': ['Japan'],\n",
    "    'Germany': ['Germany'],\n",
    "    'India': ['India'],\n",
    "    'France': ['France'],\n",
    "    'Italy': ['Italy'],\n",
    "    'Canada': ['Canada'],\n",
    "    'Brazil': ['Brazil'],\n",
    "    'Russia': ['Russia'],\n",
    "    'South Korea': ['South Korea']\n",
    "}\n",
    "# Count mentions in headlines while keeping original country names this ensures we allow varriants\n",
    "country_mentions = {}\n",
    "for country, variants in country_variants.items():\n",
    "    total = 0\n",
    "    for variant in variants:\n",
    "        pattern = r'\\b' + re.escape(variant) + r'\\b'\n",
    "        count = df['headline'].str.contains(pattern, case=False, regex=True).sum()\n",
    "        total += count\n",
    "    country_mentions[country] = total\n",
    "\n",
    "# Prepare data for plotting\n",
    "mentions_counts = [country_mentions[country] for country in target_countries]\n",
    "\n",
    "# Filter GDP data for our target countries and maintain order\n",
    "df_filtered = df_gdp_cleaned[df_gdp_cleaned['Country Name'].isin(target_countries)]\n",
    "df_filtered['Country Name'] = pd.Categorical(\n",
    "    df_filtered['Country Name'], \n",
    "    categories=target_countries,\n",
    "    ordered=True\n",
    ")\n",
    "df_filtered = df_filtered.sort_values('Country Name')\n",
    "\n",
    "#combined figure\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# First subplot \n",
    "plt.subplot(2, 1, 1)\n",
    "bars = plt.bar(target_countries, mentions_counts, color=plt.cm.tab20.colors[:12])\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "# Add smoothed line\n",
    "mentions_smoothed = lowess(mentions_counts, np.arange(len(target_countries)), frac=0.3)\n",
    "plt.plot(target_countries, mentions_smoothed[:, 1], color='red', lw=2, label='Trend Line')\n",
    "\n",
    "plt.title('Country Mentions in Headlines (Top 12 Economies) (2014-2023)')\n",
    "plt.ylabel('Number of Mentions')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Second subplot \n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='Country Name', y='Total GDP', data=df_filtered, palette='viridis', order=target_countries)\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total GDP in Trillions(in USD)')\n",
    "plt.title('Total GDP of Top 12 Economies (2013-2023)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "#Formatting\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df_war = pd.read_csv('/Users/georgewalsh/Documents/battle/battledata.csv',skiprows=4)  # Skip the first 4 rows which contain metadata\n",
    "df_war_cleaned = df_war[['Country Name','2014','2015','2016','2017','2018','2019', '2020', '2021', '2022','2023']]\n",
    "\n",
    "# Then do the summing\n",
    "year_columns = [str(year) for year in range(2014, 2024)]\n",
    "df_war_cleaned['Total'] = df_war_cleaned[year_columns].sum(axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df_war_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "\n",
    "\n",
    "# Define key countries and variations\n",
    "\n",
    "\n",
    "key_countries = ['Ukraine', 'Russia', 'United States', 'Sudan', 'United Kingdom',\n",
    "                 'Afghanistan', 'Ethiopia', 'Iraq']\n",
    "\n",
    "country_variations = {\n",
    "    'Ukraine': ['ukraine'],\n",
    "    'Russia': ['russia'],\n",
    "    'Iraq': ['iraq'],\n",
    "    'United Kingdom': ['united kingdom', 'uk'],\n",
    "    'United States': ['united states', 'us', 'usa'],\n",
    "    'Ethiopia': ['ethiopia'],\n",
    "    'Afghanistan': ['afghanistan'],\n",
    "    'Sudan': ['sudan']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure lowercase version of headlines\n",
    "df['headline_lower'] = df['headline'].str.lower()\n",
    "\n",
    "# Count mentions\n",
    "mention_counts = {}\n",
    "for country, variations in country_variations.items():\n",
    "    mask = df['headline_lower'].str.contains(r'\\b(war|conflict)\\b', case=False)\n",
    "    country_mask = mask & df['headline_lower'].apply(\n",
    "        lambda text: any(variant in text for variant in variations)\n",
    "    )\n",
    "    mention_counts[country] = country_mask.sum()\n",
    "\n",
    "mentions_df = pd.DataFrame(list(mention_counts.items()), columns=['Country', 'Mentions'])\n",
    "\n",
    "\n",
    "#  War Deaths \n",
    "\n",
    "\n",
    "# Filter the DataFrame to include only key countries\n",
    "df_war_subset = df_war_cleaned[df_war_cleaned['Country Name'].isin(key_countries)]\n",
    "df_war_subset = df_war_subset.sort_values('Total', ascending=False)\n",
    "# plotting\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# plot total deaths\n",
    "bars1 = ax1.bar(df_war_subset['Country Name'], df_war_subset['Total'], color='skyblue')\n",
    "ax1.set_title('Total Deaths (2014–2023)', fontsize=14)\n",
    "ax1.set_ylabel('Total Deaths')\n",
    "ax1.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height, f'{int(height):,}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "\n",
    "    \n",
    "# plot total mentions\n",
    "# Match order of countries \n",
    "mentions_df = mentions_df[mentions_df['Country'].isin(key_countries)]\n",
    "mentions_df = mentions_df.set_index('Country').loc[df_war_subset['Country Name']].reset_index()\n",
    "\n",
    "\n",
    "# Add a smooth trend line — makes it easier to spot the general pattern\n",
    "x_vals = np.arange(len(mentions_df))\n",
    "y_vals = mentions_df['Mentions'].values\n",
    "\n",
    "if len(x_vals) > 2:\n",
    "    x_smooth = np.linspace(x_vals.min(), x_vals.max(), 300)\n",
    "    spline = make_interp_spline(x_vals, y_vals, k=2)  # you can adjust 'k' for curve smoothness\n",
    "    y_smooth = spline(x_smooth)\n",
    "    ax2.plot(x_smooth, y_smooth, color='darkred', linestyle='--', linewidth=2, label='Smoothed Trend')\n",
    "    \n",
    "bars2 = ax2.bar(mentions_df['Country'], mentions_df['Mentions'], color='cornflowerblue')\n",
    "ax2.set_title('Mentions of \"War\" or \"Conflict\" in Headlines (2013-2021)', fontsize=14)\n",
    "ax2.set_ylabel('Number of Mentions')\n",
    "ax2.set_xticklabels(mentions_df['Country'], rotation=30)\n",
    "ax2.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height, f'{height}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Vote Share by Party\n",
    "# Load and process data\n",
    "df_pol = pd.read_excel('/Users/georgewalsh/Documents/pivottablefull.xlsx', header=8)\n",
    "df_vote = df_pol[df_pol['Data'] == 'Sum of Vote'][['Party', 2015, 2017, 2019]]\n",
    "\n",
    "# Calculate totals and percentages (keep as float)\n",
    "df_vote['Total Votes'] = df_vote[[2015, 2017, 2019]].sum(axis=1)\n",
    "total_all_parties = df_vote['Total Votes'].sum()\n",
    "df_vote['Percentage'] = (df_vote['Total Votes'] / total_all_parties) * 100\n",
    "\n",
    "# Clean party names\n",
    "df_vote['Party'] = df_vote['Party'].replace({\n",
    "    'CON': 'Conservative',\n",
    "    'LAB': 'Labour',\n",
    "    'LIB': 'Lib Dem',\n",
    "    'NAT': 'Scotish National Party'\n",
    "})\n",
    "\n",
    "# Filter out minor parties and others\n",
    "df_vote = df_vote[~df_vote['Party'].isin(['MIN', 'OTH'])]\n",
    "\n",
    "# Sort by numeric percentage before plotting\n",
    "df_vote = df_vote.sort_values('Percentage', ascending=False)\n",
    "\n",
    "df_2021= df[df['year'] <= 2021]\n",
    "df_vote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define regex patterns for party mentions\n",
    "patterns = {\n",
    "    'Conservative': re.compile(r'\\bConservative(s)?\\b|\\bTory\\b|\\bTories\\b', re.IGNORECASE),\n",
    "    'Labour': re.compile(r'\\bLabour\\b', re.IGNORECASE),\n",
    "    'Liberal Democrat': re.compile(r'\\bLiberal Democrat(s)?\\b|\\bLib Dem(s)?\\b', re.IGNORECASE),\n",
    "    'Scottish National Party': re.compile(r'\\bScottish National Party\\b|\\bSNP\\b', re.IGNORECASE)\n",
    "}\n",
    "\n",
    "# Plot vote share by party\n",
    "plt.figure(figsize=(14, 7))\n",
    "bars_vote = plt.bar(df_vote['Party'], df_vote['Percentage'], color=[\n",
    "    '#0087DC', '#E4003B', '#FAA61A', '#3F8428', '#6D3177', '#999999'\n",
    "])\n",
    "\n",
    "for bar in bars_vote:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}%',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.title('UK General Elections Total Vote Share by Party (2015, 2017 & 2019)', pad=20)\n",
    "plt.ylabel('Percentage of Votes (%)')\n",
    "plt.ylim(0, df_vote['Percentage'].max() + 5)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count mentions\n",
    "mention_counts = defaultdict(int)\n",
    "\n",
    "for headline in df_2021['headline']:\n",
    "    found_parties = set()\n",
    "    for party, pattern in patterns.items():\n",
    "        if pattern.search(headline):\n",
    "            found_parties.add(party)\n",
    "    for party in found_parties:\n",
    "        mention_counts[party] += 1\n",
    "\n",
    "# Convert to percentages\n",
    "count_df = pd.DataFrame.from_dict(mention_counts, orient='index', columns=['Count'])\n",
    "total_mentions = count_df['Count'].sum()\n",
    "count_df['Percentage'] = (count_df['Count'] / total_mentions) * 100\n",
    "count_df = count_df.sort_values('Percentage', ascending=False)\n",
    "\n",
    "# Define consistent colors\n",
    "colors = {\n",
    "    'Conservative': '#0087DC',\n",
    "    'Labour': '#E4003B',\n",
    "    'Liberal Democrat': '#FAA61A',\n",
    "    'Scottish National Party': '#3F8428',\n",
    "    'Green': '#6D3177',\n",
    "    'Reform UK': '#999999'\n",
    "}\n",
    "\n",
    "# Plot mention percentages\n",
    "plt.figure(figsize=(14, 7))\n",
    "bars_mentions = plt.bar(count_df.index, count_df['Percentage'], \n",
    "                        color=[colors.get(party, '#CCCCCC') for party in count_df.index])\n",
    "\n",
    "for bar in bars_mentions:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}%',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Political Party Mentions in Headlines (% of Total Mentions) (2013 and 2021)', pad=20)\n",
    "plt.ylabel('Percentage of Mentions (%)')\n",
    "plt.ylim(0, count_df['Percentage'].max() + 5)\n",
    "plt.grid(axis='y', alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot vote share by party as pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "colors_vote = ['#0087DC', '#E4003B', '#FAA61A', '#3F8428', '#6D3177', '#999999']\n",
    "plt.pie(df_vote['Percentage'], labels=df_vote['Party'], autopct='%1.1f%%',\n",
    "        colors=colors_vote, startangle=90, wedgeprops={'linewidth': 1, 'edgecolor': 'white'})\n",
    "plt.title('UK General Elections Total Vote Share by Party\\n(2015, 2017 & 2019)', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot mention percentages as pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "colors_mentions = [colors.get(party, '#CCCCCC') for party in count_df.index]\n",
    "plt.pie(count_df['Percentage'], labels=count_df.index, autopct='%1.1f%%',\n",
    "        colors=colors_mentions, startangle=90, wedgeprops={'linewidth': 1, 'edgecolor': 'white'})\n",
    "plt.title('Political Party Mentions in Headlines\\n(% of Total Mentions) (2013 and 2021)', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define main parties and consistent colors\n",
    "main_parties = ['Conservative', 'Labour', 'Liberal Democrat', 'Scottish National Party']\n",
    "colors = {\n",
    "    'Conservative': '#0087DC',\n",
    "    'Labour': '#E4003B',\n",
    "    'Liberal Democrat': '#FAA61A',\n",
    "    'Scottish National Party': '#3F8428'\n",
    "}\n",
    "\n",
    "# Filter vote share and media mentions\n",
    "df_vote_filtered = df_vote[df_vote['Party'].isin(main_parties)].set_index('Party')\n",
    "df_mentions_filtered = count_df[count_df.index.isin(main_parties)]\n",
    "\n",
    "# Prepare data\n",
    "vote_share = df_vote_filtered.loc[main_parties, 'Percentage']\n",
    "mention_share = df_mentions_filtered.loc[main_parties, 'Percentage']\n",
    "\n",
    "# Plot side-by-side pie charts\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Pie chart for Vote Share\n",
    "axs[0].pie(vote_share, labels=main_parties, autopct='%1.1f%%', startangle=140,\n",
    "           colors=[colors[party] for party in main_parties], textprops={'fontsize': 10})\n",
    "axs[0].set_title('Vote Share by Party (2015–2019)', fontsize=14)\n",
    "\n",
    "# Pie chart for Media Mentions\n",
    "axs[1].pie(mention_share, labels=main_parties, autopct='%1.1f%%', startangle=140,\n",
    "           colors=[colors[party] for party in main_parties], textprops={'fontsize': 10})\n",
    "axs[1].set_title('Media Mentions by Party (2021 Headlines)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
