{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "#set-up\n",
    "# Guardian API Key and Base URL\n",
    "API_KEY = \"998344a2-04a1-4410-9d53-1490cfa2e9d2\"\n",
    "BASE_URL = \"https://content.guardianapis.com/search\"\n",
    "# Output file\n",
    "FILE_NAME = \"guardian_articles.csv\"\n",
    "# Number of weeks to scrape\n",
    "NUM_WEEKS = 554\n",
    "\n",
    "\n",
    "# Generate random weekly dates (going backward from today)\n",
    "start_date = datetime.today()\n",
    "dates = [(start_date - timedelta(weeks=i)).strftime(\"%Y-%m-%d\") for i in range(NUM_WEEKS)]\n",
    "\n",
    "# Load existing data if the file exists\n",
    "if os.path.exists(FILE_NAME):\n",
    "    df = pd.read_csv(FILE_NAME)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"headline\", \"publication_date\", \"url\"])\n",
    "\n",
    "# Fetch articles for each week\n",
    "for week_date in dates:\n",
    "    params = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"from-date\": week_date,\n",
    "        \"to-date\": week_date,\n",
    "        \"show-fields\": \"headline\",\n",
    "        \"page-size\": 10,  # Get up to 10 articles from the date\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data[\"response\"][\"results\"]\n",
    "        \n",
    "        if articles:\n",
    "            selected_article = random.choice(articles)  # Pick one randomly\n",
    "            article_data = {\n",
    "                \"headline\": selected_article[\"webTitle\"],\n",
    "                \"publication_date\": selected_article[\"webPublicationDate\"],\n",
    "                \"url\": selected_article[\"webUrl\"],\n",
    "            }\n",
    "\n",
    "            # Append new data and save\n",
    "            df = pd.concat([df, pd.DataFrame([article_data])], ignore_index=True)\n",
    "            df.to_csv(FILE_NAME, index=False)\n",
    "\n",
    "            print(f\"Saved article from {week_date}: {article_data['headline']}\")\n",
    "        else:\n",
    "            print(f\"No articles found for {week_date}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {week_date}: {response.status_code}\")\n",
    "\n",
    "print(\" Data collection complete!\")\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1. Ensure datetime format\n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'])\n",
    "\n",
    "# 2. Extract year and month name\n",
    "df['year'] = df['publication_date'].dt.year\n",
    "df['month'] = df['publication_date'].dt.month_name()\n",
    "\n",
    "# 3. Group by year and month to count entries\n",
    "monthly_distribution = df.groupby(['year', 'month']).size().reset_index(name='count')\n",
    "\n",
    "# 4. Ensure consistent month order\n",
    "month_order = [\n",
    "    'January', 'February', 'March', 'April', 'May', 'June',\n",
    "    'July', 'August', 'September', 'October', 'November', 'December'\n",
    "]\n",
    "monthly_distribution['month'] = pd.Categorical(monthly_distribution['month'], categories=month_order, ordered=True)\n",
    "\n",
    "# 5. Create figure and boxplot\n",
    "plt.figure(figsize=(16, 7))\n",
    "ax = sns.boxplot(\n",
    "    data=monthly_distribution,\n",
    "    x='month',\n",
    "    y='count',\n",
    "    palette='pastel',\n",
    "    linewidth=1.2,\n",
    "    fliersize=3\n",
    ")\n",
    "\n",
    "# 6. Calculate stats and annotate\n",
    "for i, month in enumerate(month_order):\n",
    "    month_data = monthly_distribution[monthly_distribution['month'] == month]['count'].dropna()\n",
    "    if len(month_data) == 0:\n",
    "        continue\n",
    "\n",
    "    q1 = np.percentile(month_data, 25)\n",
    "    q3 = np.percentile(month_data, 75)\n",
    "    median = np.median(month_data)\n",
    "    whisker_low = month_data[month_data >= q1 - 1.5 * (q3 - q1)].min()\n",
    "    whisker_high = month_data[month_data <= q3 + 1.5 * (q3 - q1)].max()\n",
    "\n",
    "    # Annotate\n",
    "    ax.text(i, median, f'Median: {int(median)}', ha='center', va='center', fontsize=9, color='black', weight='bold')\n",
    "    ax.text(i, q1, f'Q1: {int(q1)}', ha='center', va='top', fontsize=8, color='darkblue')\n",
    "    ax.text(i, q3, f'Q3: {int(q3)}', ha='center', va='bottom', fontsize=8, color='darkgreen')\n",
    "    ax.text(i, whisker_low, f'Min: {int(whisker_low)}', ha='center', va='top', fontsize=8, color='gray')\n",
    "    ax.text(i, whisker_high, f'Max: {int(whisker_high)}', ha='center', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "# 7. Final styling\n",
    "plt.title(\"Box Plot of Monthly Entry Counts Across Years\\nwith Median, Quartiles and Whiskers\", fontsize=16, weight='bold', pad=20)\n",
    "plt.xlabel(\"Month\", fontsize=12)\n",
    "plt.ylabel(\"Number of Entries per Year\", fontsize=12)\n",
    "plt.xticks(rotation=45, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "sns.despine(top=True, right=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Convert to datetime if needed\n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'])\n",
    "\n",
    "# 2. Extract year\n",
    "df['year'] = df['publication_date'].dt.year\n",
    "\n",
    "# 3. Count entries per year\n",
    "year_counts = df['year'].value_counts().sort_index()\n",
    "year_index = year_counts.index.astype(str)\n",
    "year_values = year_counts.values\n",
    "\n",
    "# 4. Generate unique colors\n",
    "colors = sns.color_palette(\"tab10\", len(year_counts))\n",
    "\n",
    "# 5. Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Bar chart\n",
    "bars = plt.bar(\n",
    "    year_index,\n",
    "    year_values,\n",
    "    color=colors,\n",
    "    edgecolor='white',\n",
    "    width=0.6,\n",
    "    label='Entries'\n",
    ")\n",
    "\n",
    "# Smoothed line of best fit\n",
    "sns.lineplot(\n",
    "    x=year_index,\n",
    "    y=year_values,\n",
    "    color='black',\n",
    "    linewidth=1,\n",
    "    label='Trend'\n",
    ")\n",
    "\n",
    "# Add value labels above each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 1,\n",
    "        f'{height}',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "# Styling\n",
    "plt.title(\"Entries Per Year with Trend Line\", fontsize=16, weight='bold', pad=15)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Number of Entries\", fontsize=12)\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "sns.despine(top=True, right=True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df_gdp = pd.read_csv('/Users/georgewalsh/Desktop/API_NY/GDP.csv', skiprows=4)  # Skip the first 4 rows which contain metadata\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df_gdp.head()\n",
    "\n",
    "df_gdp_cleaned = df_gdp[['Country Name','2014','2015','2016','2017','2018','2019', '2020', '2021', '2022','2023']]\n",
    "\n",
    "\n",
    "# Convert all GDP values (2019-2023) to numeric (integers or floats)\n",
    "gdp_columns = ['2014','2015','2016','2017','2018','2019', '2020', '2021', '2022', '2023']\n",
    "df_gdp_cleaned[gdp_columns] = df_gdp_cleaned[gdp_columns].apply(pd.to_numeric, errors='coerce')  # Convert values\n",
    "\n",
    "# Create a new column summarizing the total GDP over all years\n",
    "df_gdp_cleaned['Total GDP'] = df_gdp_cleaned[gdp_columns].sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_gdp_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this allows us to incorporate the smoothed line of best fit\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "# Define our target countries (in the order we want them displayed)\n",
    "target_countries = [\n",
    "    'United States', 'China', 'Japan', 'Germany', \n",
    "    'India', 'United Kingdom', 'France', 'Italy',\n",
    "    'Canada', 'Brazil', 'Russia', 'South Korea'\n",
    "]\n",
    "# Country variants to search for in headlines\n",
    "country_variants = {\n",
    "    'United States': ['United States', 'USA', 'US', 'America'],\n",
    "    'United Kingdom': ['United Kingdom', 'UK', 'Britain'],\n",
    "    'China': ['China'],\n",
    "    'Japan': ['Japan'],\n",
    "    'Germany': ['Germany'],\n",
    "    'India': ['India'],\n",
    "    'France': ['France'],\n",
    "    'Italy': ['Italy'],\n",
    "    'Canada': ['Canada'],\n",
    "    'Brazil': ['Brazil'],\n",
    "    'Russia': ['Russia'],\n",
    "    'South Korea': ['South Korea']\n",
    "}\n",
    "# Count mentions in headlines while keeping original country names this ensures we allow varriants\n",
    "country_mentions = {}\n",
    "for country, variants in country_variants.items():\n",
    "    total = 0\n",
    "    for variant in variants:\n",
    "        pattern = r'\\b' + re.escape(variant) + r'\\b'\n",
    "        count = df['headline'].str.contains(pattern, case=False, regex=True).sum()\n",
    "        total += count\n",
    "    country_mentions[country] = total\n",
    "\n",
    "# Prepare data for plotting\n",
    "mentions_counts = [country_mentions[country] for country in target_countries]\n",
    "\n",
    "# Filter GDP data for our target countries and maintain order\n",
    "df_filtered = df_gdp_cleaned[df_gdp_cleaned['Country Name'].isin(target_countries)]\n",
    "df_filtered['Country Name'] = pd.Categorical(\n",
    "    df_filtered['Country Name'], \n",
    "    categories=target_countries,\n",
    "    ordered=True\n",
    ")\n",
    "df_filtered = df_filtered.sort_values('Country Name')\n",
    "\n",
    "#combined figure\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# First subplot \n",
    "plt.subplot(2, 1, 1)\n",
    "bars = plt.bar(target_countries, mentions_counts, color=plt.cm.tab20.colors[:12])\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "# Add smoothed line\n",
    "mentions_smoothed = lowess(mentions_counts, np.arange(len(target_countries)), frac=0.3)\n",
    "plt.plot(target_countries, mentions_smoothed[:, 1], color='red', lw=2, label='Trend Line')\n",
    "\n",
    "plt.title('Country Mentions in Headlines (Top 12 Economies)')\n",
    "plt.ylabel('Number of Mentions')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Second subplot \n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='Country Name', y='Total GDP', data=df_filtered, palette='viridis', order=target_countries)\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total GDP in Trillions(in USD)')\n",
    "plt.title('Total GDP of Top 12 Economies')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "#Formatting\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df_war = pd.read_csv('/Users/georgewalsh/Documents/battle/battledata.csv',skiprows=4)  # Skip the first 4 rows which contain metadata\n",
    "df_war_cleaned = df_war[['Country Name','2014','2015','2016','2017','2018','2019', '2020', '2021', '2022','2023']]\n",
    "\n",
    "# Then do the summing\n",
    "year_columns = [str(year) for year in range(2014, 2024)]\n",
    "df_war_cleaned['Total'] = df_war_cleaned[year_columns].sum(axis=1)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df_war_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define key countries and variations\n",
    "\n",
    "\n",
    "key_countries = ['Ukraine', 'Russia', 'United States', 'Sudan', 'United Kingdom',\n",
    "                 'Afghanistan', 'Ethiopia', 'Iraq']\n",
    "\n",
    "country_variations = {\n",
    "    'Ukraine': ['ukraine'],\n",
    "    'Russia': ['russia'],\n",
    "    'Iraq': ['iraq'],\n",
    "    'United Kingdom': ['united kingdom', 'uk'],\n",
    "    'United States': ['united states', 'us', 'usa'],\n",
    "    'Ethiopia': ['ethiopia'],\n",
    "    'Afghanistan': ['afghanistan'],\n",
    "    'Sudan': ['sudan']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure lowercase version of headlines\n",
    "df['headline_lower'] = df['headline'].str.lower()\n",
    "\n",
    "# Count mentions\n",
    "mention_counts = {}\n",
    "for country, variations in country_variations.items():\n",
    "    mask = df['headline_lower'].str.contains(r'\\b(war|conflict)\\b', case=False)\n",
    "    country_mask = mask & df['headline_lower'].apply(\n",
    "        lambda text: any(variant in text for variant in variations)\n",
    "    )\n",
    "    mention_counts[country] = country_mask.sum()\n",
    "\n",
    "mentions_df = pd.DataFrame(list(mention_counts.items()), columns=['Country', 'Mentions'])\n",
    "\n",
    "\n",
    "#  War Deaths \n",
    "\n",
    "\n",
    "# Filter the DataFrame to include only key countries\n",
    "df_war_subset = df_war_cleaned[df_war_cleaned['Country Name'].isin(key_countries)]\n",
    "df_war_subset = df_war_subset.sort_values('Total', ascending=False)\n",
    "# plotting\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# plot total deaths\n",
    "bars1 = ax1.bar(df_war_subset['Country Name'], df_war_subset['Total'], color='skyblue')\n",
    "ax1.set_title('Total Deaths (2014–2023)', fontsize=14)\n",
    "ax1.set_ylabel('Total Deaths')\n",
    "ax1.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height, f'{int(height):,}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "\n",
    "    \n",
    "# plot total mentions\n",
    "# Match order of countries \n",
    "mentions_df = mentions_df[mentions_df['Country'].isin(key_countries)]\n",
    "mentions_df = mentions_df.set_index('Country').loc[df_war_subset['Country Name']].reset_index()\n",
    "\n",
    "\n",
    "# Add a smooth trend line — makes it easier to spot the general pattern\n",
    "x_vals = np.arange(len(mentions_df))\n",
    "y_vals = mentions_df['Mentions'].values\n",
    "\n",
    "if len(x_vals) > 2:\n",
    "    x_smooth = np.linspace(x_vals.min(), x_vals.max(), 300)\n",
    "    spline = make_interp_spline(x_vals, y_vals, k=2)  # you can adjust 'k' for curve smoothness\n",
    "    y_smooth = spline(x_smooth)\n",
    "    ax2.plot(x_smooth, y_smooth, color='darkred', linestyle='--', linewidth=2, label='Smoothed Trend')\n",
    "    \n",
    "bars2 = ax2.bar(mentions_df['Country'], mentions_df['Mentions'], color='cornflowerblue')\n",
    "ax2.set_title('Mentions of \"War\" or \"Conflict\" in Headlines', fontsize=14)\n",
    "ax2.set_ylabel('Number of Mentions')\n",
    "ax2.set_xticklabels(mentions_df['Country'], rotation=30)\n",
    "ax2.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height, f'{height}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Vote Share by Party\n",
    "# Load and process data\n",
    "df_pol = pd.read_excel('/Users/georgewalsh/Documents/pivottablefull.xlsx', header=8)\n",
    "df_vote = df_pol[df_pol['Data'] == 'Sum of Vote'][['Party', 2015, 2017, 2019]]\n",
    "\n",
    "# Calculate totals and percentages (keep as float)\n",
    "df_vote['Total Votes'] = df_vote[[2015, 2017, 2019]].sum(axis=1)\n",
    "total_all_parties = df_vote['Total Votes'].sum()\n",
    "df_vote['Percentage'] = (df_vote['Total Votes'] / total_all_parties) * 100\n",
    "\n",
    "# Clean party names\n",
    "df_vote['Party'] = df_vote['Party'].replace({\n",
    "    'CON': 'Conservative',\n",
    "    'LAB': 'Labour',\n",
    "    'LIB': 'Lib Dem',\n",
    "    'NAT': 'Scotish National Party'\n",
    "})\n",
    "\n",
    "# Filter out minor parties and others\n",
    "df_vote = df_vote[~df_vote['Party'].isin(['MIN', 'OTH'])]\n",
    "\n",
    "# Sort by numeric percentage before plotting\n",
    "df_vote = df_vote.sort_values('Percentage', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#this plots the vote share by party\n",
    "plt.figure(figsize=(14, 7))\n",
    "bars_vote = plt.bar(df_vote['Party'], df_vote['Percentage'], color=[\n",
    "    '#0087DC', '#E4003B', '#FAA61A', '#3F8428','#6D3177','#999999'\n",
    "])\n",
    "\n",
    "for bar in bars_vote:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}%',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.title('UK General Elections Total Vote Share by Party', pad=20)\n",
    "plt.ylabel('Percentage of Votes (%)')\n",
    "plt.ylim(0, df_vote['Percentage'].max() + 5)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Count mentions\n",
    "mention_counts = defaultdict(int)\n",
    "\n",
    "for headline in df['headline']:\n",
    "    found_parties = set()\n",
    "    for party, pattern in patterns.items():\n",
    "        if pattern.search(headline):\n",
    "            found_parties.add(party)\n",
    "    for party in found_parties:\n",
    "        mention_counts[party] += 1\n",
    "\n",
    "# Convert to percentages\n",
    "count_df = pd.DataFrame.from_dict(mention_counts, orient='index', columns=['Count'])\n",
    "total_mentions = count_df['Count'].sum()\n",
    "count_df['Percentage'] = (count_df['Count'] / total_mentions) * 100\n",
    "count_df = count_df.sort_values('Percentage', ascending=False)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(14, 7))\n",
    "colors = {\n",
    "    'Conservative': '#0087DC',\n",
    "    'Labour': '#E4003B',\n",
    "    'Liberal Democrat': '#FAA61A',\n",
    "    'Scotish National Party': '#3F8428'  \n",
    "}\n",
    "\n",
    "bars_mentions = plt.bar(count_df.index, count_df['Percentage'], \n",
    "                       color=[colors[p] for p in count_df.index])\n",
    "\n",
    "for bar in bars_mentions:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}%',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Political Party Mentions in Headlines (% of Total Mentions)', pad=20)\n",
    "plt.ylabel('Percentage of Mentions (%)')\n",
    "plt.ylim(0, count_df['Percentage'].max() + 5)\n",
    "plt.grid(axis='y', alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Combine all headlines into a single string\n",
    "text = \" \".join(headline for headline in df['headline'].dropna())\n",
    "\n",
    "# Optional: Clean up text (remove common stopwords)\n",
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# Step 2: Create the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400,\n",
    "                      background_color='white',\n",
    "                      stopwords=stopwords,\n",
    "                      colormap='viridis').generate(text)\n",
    "\n",
    "# Step 3: Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Most Frequent Words in Headlines')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Combine all headlines into a single string\n",
    "text = \" \".join(headline for headline in df['headline'].dropna())\n",
    "\n",
    "# Step 2: Clean up stopwords and irrelevant words\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"s\", \"said\", \"mr\", \"mrs\",\n",
    "                  \"says\",\"will\",\"happened\",\"review\",\n",
    "                  \"quick\",\"U\",\"new\",\"crossword\", \"Cryptic\",\"\"\n",
    "                  \"day\",\"call\",\"year\"])  # Add more custom stopwords if needed\n",
    "\n",
    "# Step 3: Create the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400,\n",
    "                      background_color='white',\n",
    "                      stopwords=stopwords,\n",
    "                      colormap='viridis').generate(text)\n",
    "\n",
    "# Step 4: Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Most Frequent Words in Headlines')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"evangower/premier-league-matches-19922022\")\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footy=pd.read_csv(\"/Users/georgewalsh/Documents/premier-league-matches.csv\")\n",
    "df_footy_filtered = df_footy[df_footy['Season_End_Year'] >= 2016]\n",
    "df_footy_filtered.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Home team wins\n",
    "home_wins = df_footy_filtered[df_footy_filtered['HomeGoals'] > df_footy_filtered['AwayGoals']]\n",
    "home_win_counts = home_wins['Home'].value_counts()\n",
    "\n",
    "# Away team wins\n",
    "away_wins = df_footy_filtered[df_footy_filtered['AwayGoals'] > df_footy_filtered['HomeGoals']]\n",
    "away_win_counts = away_wins['Away'].value_counts()\n",
    "\n",
    "# Combine home and away wins\n",
    "total_wins = home_win_counts.add(away_win_counts, fill_value=0).astype(int)\n",
    "\n",
    "# Create the new DataFrame\n",
    "df_team_wins = total_wins.reset_index()\n",
    "df_team_wins.columns = ['team', 'wins']\n",
    "\n",
    "# Sort by number of wins (optional)\n",
    "df_team_wins = df_team_wins.sort_values(by='wins', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_team_wins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a combined list of all unique teams from both datasets\n",
    "all_teams = sorted(list(set(df_team_wins_sorted['team'].unique()).union(set(prem_teams))))\n",
    "\n",
    "# Create a consistent color palette for all teams\n",
    "team_colors = sns.color_palette(\"hsv\", len(all_teams))\n",
    "color_dict = {team: color for team, color in zip(all_teams, team_colors)}\n",
    "\n",
    "# Define a small offset for the value labels\n",
    "offset = 3\n",
    "\n",
    "# First plot: Total Wins by Team\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Horizontal lines, dots, and value labels - using the consistent color mapping\n",
    "for team, wins in zip(df_team_wins_sorted['team'], df_team_wins_sorted['wins']):\n",
    "    plt.hlines(y=team, xmin=0, xmax=wins, color=color_dict[team], linewidth=2)\n",
    "    plt.plot(wins, team, \"o\", color=color_dict[team], markersize=8)\n",
    "    # Place the value label to the left of the bar and in black\n",
    "    plt.text(wins + offset, team, str(wins), va='center', ha='left', fontsize=10, color='black')\n",
    "\n",
    "plt.xlabel(\"Total Wins\")\n",
    "plt.title(\"Total Wins by Team\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(0, 230, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Second plot: Team Mentions in Headlines\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Draw horizontal lines, dots, and value labels - using the same color mapping\n",
    "for team, mentions in zip(df_mentions['team'], df_mentions['mentions']):\n",
    "    plt.hlines(y=team, xmin=0, xmax=mentions, color=color_dict[team], linewidth=2)\n",
    "    plt.plot(mentions, team, \"o\", color=color_dict[team], markersize=8)\n",
    "    # Place the value label to the left of the bar and in black\n",
    "    plt.text(mentions +  offset, team, str(mentions), va='center', ha='left', fontsize=10, color='black')\n",
    "\n",
    "plt.xlabel(\"Number of Mentions in Headlines\")\n",
    "plt.title(\"Premier League Team Mentions in Headlines\", fontsize=14)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "plt.xticks(np.arange(0, 130, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
