{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Guardian API Key and Base URL\n",
    "API_KEY = \"998344a2-04a1-4410-9d53-1490cfa2e9d2\"\n",
    "BASE_URL = \"https://content.guardianapis.com/search\"\n",
    "\n",
    "# Output file\n",
    "FILE_NAME = \"guardian_articles.csv\"\n",
    "\n",
    "# Number of weeks to scrape\n",
    "NUM_WEEKS = 580\n",
    "ARTICLES_PER_WEEK = 100\n",
    "\n",
    "# Generate random weekly dates (going backward from today)\n",
    "start_date = datetime.today()\n",
    "dates = [(start_date - timedelta(weeks=i)).strftime(\"%Y-%m-%d\") for i in range(NUM_WEEKS)]\n",
    "\n",
    "# Load existing data if the file exists\n",
    "if os.path.exists(FILE_NAME):\n",
    "    df = pd.read_csv(FILE_NAME)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"headline\", \"publication_date\", \"url\"])\n",
    "\n",
    "# Fetch articles for each week\n",
    "for week_date in dates:\n",
    "    params = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"from-date\": week_date,\n",
    "        \"to-date\": week_date,\n",
    "        \"show-fields\": \"headline\",\n",
    "        \"page-size\": 10,  # Get up to 10 articles from the date\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data[\"response\"][\"results\"]\n",
    "        \n",
    "        if articles:\n",
    "            selected_article = random.choice(articles)  # Pick one randomly\n",
    "            article_data = {\n",
    "                \"headline\": selected_article[\"webTitle\"],\n",
    "                \"publication_date\": selected_article[\"webPublicationDate\"],\n",
    "                \"url\": selected_article[\"webUrl\"],\n",
    "            }\n",
    "\n",
    "            # Append new data and save\n",
    "            df = pd.concat([df, pd.DataFrame([article_data])], ignore_index=True)\n",
    "            df.to_csv(FILE_NAME, index=False)\n",
    "\n",
    "            print(f\"Saved article from {week_date}: {article_data['headline']}\")\n",
    "        else:\n",
    "            print(f\"No articles found for {week_date}.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {week_date}: {response.status_code}\")\n",
    "\n",
    "print(\" Data collection complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this allows us to test the sucess of our scrapinng and ensure it has gone back 500 weeks also that it was effectively formatted\n",
    "# Using .shape to get the number of rows and columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have a DataFrame called 'df' with a 'title' column\n",
    "# If not, you would load your data first:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# List of keywords to search for\n",
    "keywords = ['economy', 'inflation', 'recession', \n",
    "            'pandemic', 'war', 'conflict',\n",
    "            'trade','death','aid','attack',\n",
    "            'election','debt',\n",
    "            'crime','healthcare',\n",
    "            'education',\n",
    "]\n",
    "\n",
    "# Create a function to count keyword occurrences\n",
    "def count_keywords(df, column_name, keywords):\n",
    "    keyword_counts = {}\n",
    "    \n",
    "    # Convert titles to lowercase for case-insensitive search\n",
    "    titles = df[column_name].str.lower()\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        # Count how many titles contain the keyword\n",
    "        count = titles.str.contains(keyword).sum()\n",
    "        keyword_counts[keyword] = count\n",
    "    \n",
    "    return keyword_counts\n",
    "\n",
    "# Get keyword counts\n",
    "keyword_counts = count_keywords(df, 'headline', keywords)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_data = pd.DataFrame.from_dict(keyword_counts, orient='index', columns=['count'])\n",
    "plot_data = plot_data.sort_values('count', ascending=False)\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=plot_data.index, y=plot_data['count'], palette='viridis')\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Frequency of Keywords in Titles', fontsize=16)\n",
    "plt.xlabel('Keywords', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='center', \n",
    "                xytext=(0, 5), \n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df_gdp = pd.read_csv('/Users/georgewalsh/Desktop/API_NY/GDP.csv', skiprows=4)  # Skip the first 4 rows which contain metadata\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df_gdp.head()\n",
    "\n",
    "df_gdp_cleaned = df_gdp[['Country Name','2014','2015','2016','2017','2018','2019', '2020', '2021', '2022','2023']]\n",
    "df_gdp_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all GDP values (2019-2023) to numeric (integers or floats)\n",
    "gdp_columns = ['2014','2015','2016','2017','2018','2019', '2020', '2021', '2022', '2023']\n",
    "df_gdp_cleaned[gdp_columns] = df_gdp_cleaned[gdp_columns].apply(pd.to_numeric, errors='coerce')  # Convert values\n",
    "\n",
    "# Create a new column summarizing the total GDP over all years\n",
    "df_gdp_cleaned['Total GDP'] = df_gdp_cleaned[gdp_columns].sum(axis=1)\n",
    "\n",
    "# Convert column names (years) to strings before melting\n",
    "df_gdp_cleaned.columns = df_gdp_cleaned.columns.astype(str)\n",
    "\n",
    "# Reshape the dataframe for visualization\n",
    "df_gdp_melted = df_gdp_cleaned.melt(id_vars=['Country Name', 'Total GDP'], var_name='Year', value_name='GDP')\n",
    "\n",
    "df_gdp_melted['Country Name'] = df_gdp_melted['Country Name'].replace('United Kingdom', 'UK')\n",
    "df_gdp_melted[df_gdp_melted[\"Country Name\"] == \"UK\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this allows us to incorporate the smoothed line of best fit\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "# Define our target countries (in the order we want them displayed)\n",
    "target_countries = [\n",
    "    'United States', 'China', 'Japan', 'Germany', \n",
    "    'India', 'United Kingdom', 'France', 'Italy',\n",
    "    'Canada', 'Brazil', 'Russia', 'South Korea'\n",
    "]\n",
    "# Country variants to search for in headlines\n",
    "country_variants = {\n",
    "    'United States': ['United States', 'USA', 'US', 'America'],\n",
    "    'United Kingdom': ['United Kingdom', 'UK', 'Britain'],\n",
    "    'China': ['China'],\n",
    "    'Japan': ['Japan'],\n",
    "    'Germany': ['Germany'],\n",
    "    'India': ['India'],\n",
    "    'France': ['France'],\n",
    "    'Italy': ['Italy'],\n",
    "    'Canada': ['Canada'],\n",
    "    'Brazil': ['Brazil'],\n",
    "    'Russia': ['Russia'],\n",
    "    'South Korea': ['South Korea']\n",
    "}\n",
    "# Count mentions in headlines while keeping original country names this ensures we allow varriants\n",
    "country_mentions = {}\n",
    "for country, variants in country_variants.items():\n",
    "    total = 0\n",
    "    for variant in variants:\n",
    "        pattern = r'\\b' + re.escape(variant) + r'\\b'\n",
    "        count = df['headline'].str.contains(pattern, case=False, regex=True).sum()\n",
    "        total += count\n",
    "    country_mentions[country] = total\n",
    "\n",
    "# Prepare data for plotting\n",
    "mentions_counts = [country_mentions[country] for country in target_countries]\n",
    "\n",
    "# Filter GDP data for our target countries and maintain order\n",
    "df_filtered = df_gdp_cleaned[df_gdp_cleaned['Country Name'].isin(target_countries)]\n",
    "df_filtered['Country Name'] = pd.Categorical(\n",
    "    df_filtered['Country Name'], \n",
    "    categories=target_countries,\n",
    "    ordered=True\n",
    ")\n",
    "df_filtered = df_filtered.sort_values('Country Name')\n",
    "\n",
    "#combined figure\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# First subplot \n",
    "plt.subplot(2, 1, 1)\n",
    "bars = plt.bar(target_countries, mentions_counts, color=plt.cm.tab20.colors[:12])\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "# Add smoothed line\n",
    "mentions_smoothed = lowess(mentions_counts, np.arange(len(target_countries)), frac=0.3)\n",
    "plt.plot(target_countries, mentions_smoothed[:, 1], color='red', lw=2, label='Trend Line')\n",
    "\n",
    "plt.title('Country Mentions in Headlines (Top 12 Economies)')\n",
    "plt.ylabel('Number of Mentions')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Second subplot \n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x='Country Name', y='Total GDP', data=df_filtered, palette='viridis', order=target_countries)\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total GDP in Trillions(in USD)')\n",
    "plt.title('Total GDP of Top 12 Economies')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "#Formatting\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df_war = pd.read_csv('/Users/georgewalsh/Documents/battle/battledata.csv',skiprows=4)  # Skip the first 4 rows which contain metadata\n",
    "df_war_cleaned = df_war[['Country Name','2014','2015','2016','2017','2018','2019', '2020', '2021', '2022','2023']]\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df_war_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Then do the summing\n",
    "year_columns = [str(year) for year in range(2014, 2024)]\n",
    "df_war_cleaned['Total'] = df_war_cleaned[year_columns].sum(axis=1)\n",
    "\n",
    "# Corrected code to filter rows where 'Country Name' is \"Russia\"\n",
    "df_russia = df_war_cleaned[df_war_cleaned['Country Name'] == \"United States\"]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "df_russia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define key countries and variations\n",
    "\n",
    "\n",
    "key_countries = ['Ukraine', 'Russia', 'United States', 'Sudan', 'United Kingdom',\n",
    "                 'Afghanistan', 'Ethiopia', 'Iraq']\n",
    "\n",
    "country_variations = {\n",
    "    'Ukraine': ['ukraine'],\n",
    "    'Russia': ['russia'],\n",
    "    'Iraq': ['iraq'],\n",
    "    'United Kingdom': ['united kingdom', 'uk'],\n",
    "    'United States': ['united states', 'us', 'usa'],\n",
    "    'Ethiopia': ['ethiopia'],\n",
    "    'Afghanistan': ['afghanistan'],\n",
    "    'Sudan': ['sudan']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure lowercase version of headlines\n",
    "df['headline_lower'] = df['headline'].str.lower()\n",
    "\n",
    "# Count mentions\n",
    "mention_counts = {}\n",
    "for country, variations in country_variations.items():\n",
    "    mask = df['headline_lower'].str.contains(r'\\b(war|conflict)\\b', case=False)\n",
    "    country_mask = mask & df['headline_lower'].apply(\n",
    "        lambda text: any(variant in text for variant in variations)\n",
    "    )\n",
    "    mention_counts[country] = country_mask.sum()\n",
    "\n",
    "mentions_df = pd.DataFrame(list(mention_counts.items()), columns=['Country', 'Mentions'])\n",
    "\n",
    "\n",
    "#  War Deaths \n",
    "\n",
    "\n",
    "# Filter the DataFrame to include only key countries\n",
    "df_war_subset = df_war_cleaned[df_war_cleaned['Country Name'].isin(key_countries)]\n",
    "df_war_subset = df_war_subset.sort_values('Total', ascending=False)\n",
    "# plotting\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# plot total deaths\n",
    "bars1 = ax1.bar(df_war_subset['Country Name'], df_war_subset['Total'], color='skyblue')\n",
    "ax1.set_title('Total Deaths (2014–2023)', fontsize=14)\n",
    "ax1.set_ylabel('Total Deaths')\n",
    "ax1.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height, f'{int(height):,}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "\n",
    "    \n",
    "# plot total mentions\n",
    "# Match order of countries \n",
    "mentions_df = mentions_df[mentions_df['Country'].isin(key_countries)]\n",
    "mentions_df = mentions_df.set_index('Country').loc[df_war_subset['Country Name']].reset_index()\n",
    "\n",
    "\n",
    "# Add a smooth trend line — makes it easier to spot the general pattern\n",
    "x_vals = np.arange(len(mentions_df))\n",
    "y_vals = mentions_df['Mentions'].values\n",
    "\n",
    "if len(x_vals) > 2:\n",
    "    x_smooth = np.linspace(x_vals.min(), x_vals.max(), 300)\n",
    "    spline = make_interp_spline(x_vals, y_vals, k=2)  # you can adjust 'k' for curve smoothness\n",
    "    y_smooth = spline(x_smooth)\n",
    "    ax2.plot(x_smooth, y_smooth, color='darkred', linestyle='--', linewidth=2, label='Smoothed Trend')\n",
    "    \n",
    "bars2 = ax2.bar(mentions_df['Country'], mentions_df['Mentions'], color='cornflowerblue')\n",
    "ax2.set_title('Mentions of \"War\" or \"Conflict\" in Headlines', fontsize=14)\n",
    "ax2.set_ylabel('Number of Mentions')\n",
    "ax2.set_xticklabels(mentions_df['Country'], rotation=30)\n",
    "ax2.grid(axis='y', linestyle=':', alpha=0.5)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height, f'{height}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file, skipping initial blank rows\n",
    "df_pol = pd.read_excel('/Users/georgewalsh/Documents/pivottablefull.xlsx', sheet_name='Sheet1', header=8)\n",
    "df_pol_cleaned = df_pol[['Party',\"Data\",2015,2017,2019]]\n",
    "df_vote= df_pol_cleaned[df_pol_cleaned['Data'] == 'Sum of Vote']\n",
    "\n",
    "\n",
    "#replace party abbreviations with full names\n",
    "df_vote['Party'] = df_vote['Party'].replace({'CON': 'Conservative', 'LAB': 'Labour', 'LIB': 'Liberal Democrats','MIN': 'Minority Parties','NAT': 'British National Party','OTH':\"Other\"})\n",
    "\n",
    "df_vote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
